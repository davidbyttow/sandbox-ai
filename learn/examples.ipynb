{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6729b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: y=-0.02069247170341442 + 0.8260516126036489*x + 0.0035697956930543823*x^2 + -0.08896511325039225*x^3\n",
      "actual sin(2)=0.9092974268256817, pred sin(2)=0.9339690302729629\n"
     ]
    }
   ],
   "source": [
    "# numpy only\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# values from -pi to pi for input\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# random weights\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-6\n",
    "iters = 2000\n",
    "for t in range(iters):\n",
    "  # forward pass to compute predicted y\n",
    "  y_pred = a + b*x + c*x**2 + d*x**3\n",
    "\n",
    "  # compute loss square sum of differences\n",
    "  loss = np.square(y_pred - y).sum()\n",
    "\n",
    "  # back propagation to compute gradients\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_a = grad_y_pred.sum()\n",
    "  grad_b = (grad_y_pred * x).sum()\n",
    "  grad_c = (grad_y_pred * x**2).sum()\n",
    "  grad_d = (grad_y_pred * x**3).sum()\n",
    "  \n",
    "  # update weights\n",
    "  a -= lr * grad_a\n",
    "  b -= lr * grad_b\n",
    "  c -= lr * grad_c\n",
    "  d -= lr * grad_d\n",
    "\n",
    "print(f'result: y={a} + {b}*x + {c}*x^2 + {d}*x^3')\n",
    "\n",
    "\n",
    "act = math.sin(2)\n",
    "pred = a + b*2 + c*2**2 + d*2**3\n",
    "print(f'actual sin(2)={act}, pred sin(2)={pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6589936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: y=-0.01740901544690132 + 0.8315060138702393*x + 0.0030033451039344072*x^2 + -0.08974095433950424*x^3\n",
      "actual sin(2)=0.9092974268256817, pred sin(2)=0.9396888613700867\n"
     ]
    }
   ],
   "source": [
    "# tensors only\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "a = torch.randn((), dtype=dtype)\n",
    "b = torch.randn((), dtype=dtype)\n",
    "c = torch.randn((), dtype=dtype)\n",
    "d = torch.randn((), dtype=dtype)\n",
    "\n",
    "lr = 1e-6\n",
    "iters = 2000\n",
    "for t in range(iters):\n",
    "  y_pred = a + b*x + c*x**2 + d*x**3\n",
    "  \n",
    "  loss = (y_pred - y).pow(2).sum().item()\n",
    "\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_a = grad_y_pred.sum()\n",
    "  grad_b = (grad_y_pred * x).sum()\n",
    "  grad_c = (grad_y_pred * x**2).sum()\n",
    "  grad_d = (grad_y_pred * x**3).sum()\n",
    "\n",
    "  # update weights\n",
    "  a -= lr * grad_a\n",
    "  b -= lr * grad_b\n",
    "  c -= lr * grad_c\n",
    "  d -= lr * grad_d\n",
    "\n",
    "print(f'result: y={a.item()} + {b.item()}*x + {c.item()}*x^2 + {d.item()}*x^3')\n",
    "\n",
    "act = math.sin(2)\n",
    "pred = a + b*2 + c*2**2 + d*2**3\n",
    "print(f'actual sin(2)={act}, pred sin(2)={pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4fb47f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: y=0.03807801380753517 + 0.8808224201202393*x + -0.006569087039679289*x^2 + -0.09675578027963638*x^3\n",
      "actual sin(2)=0.9092974268256817, pred sin(2)=0.9994003176689148\n"
     ]
    }
   ],
   "source": [
    "# autograd\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "dtype = torch.float\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "a = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "b = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "c = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "d = torch.randn((), dtype=dtype, requires_grad=True)\n",
    "\n",
    "lr = 1e-6\n",
    "iters = 2000\n",
    "for i in range(iters):\n",
    "  y_pred = a + b*x + c*x**2 + d*x**3\n",
    "  \n",
    "  loss = (y_pred - y).pow(2).sum()\n",
    "  \n",
    "  # computes for gradients for all tensors with required_grad=True\n",
    "  loss.backward()\n",
    "  \n",
    "  # no need to track gradients of weights\n",
    "  with torch.no_grad():\n",
    "    a -= lr * a.grad; a.grad = None\n",
    "    b -= lr * b.grad; b.grad = None\n",
    "    c -= lr * c.grad; c.grad = None\n",
    "    d -= lr * d.grad; d.grad = None\n",
    "\n",
    "print(f'result: y={a.item()} + {b.item()}*x + {c.item()}*x^2 + {d.item()}*x^3')\n",
    "\n",
    "act = math.sin(2)\n",
    "pred = a + b*2 + c*2**2 + d*2**3\n",
    "print(f'actual sin(2)={act}, pred sin(2)={pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10da86a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: y = -0.009385563433170319 + 0.842444121837616 x + 0.0016191651811823249 x^2 + -0.09129679948091507 x^3\n"
     ]
    }
   ],
   "source": [
    "# nn module\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# since output y is a linear function of (x, x^2, x^3) we can consider it \n",
    "p = torch.tensor([1, 2, 3])\n",
    "# broadcasts from a [2000, 1] to a [2000, 3]\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(3, 1),\n",
    "  torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "lr = 1e-6\n",
    "for t in range(2000):\n",
    "  y_pred = model(xx)\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  model.zero_grad()\n",
    "  loss.backward()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "      param -= lr * param.grad\n",
    "\n",
    "      \n",
    "  linear_layer = model[0]\n",
    "\n",
    "print(f'result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad9da016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: y = 0.0004977249191142619 + 0.8561056852340698 x + 0.000497750355862081 x^2 + -0.09396786242723465 x^3\n"
     ]
    }
   ],
   "source": [
    "# optim\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# since output y is a linear function of (x, x^2, x^3) we can consider it \n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  torch.nn.Linear(3, 1),\n",
    "  torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "lr = 1e-3\n",
    "iters = 2000\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "for t in range(iters):\n",
    "  y_pred = model(xx)\n",
    "  \n",
    "  loss = loss_fn(y_pred, y)\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  optimizer.step()\n",
    "\n",
    "linear_layer = model[0]\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c920ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
